# FAQ - Preguntas Frecuentes

---

## ğŸ¤” General

### **Â¿QuÃ© es este proyecto?**

Un sistema de chatbot con RAG (Retrieval Augmented Generation) que permite:

- Chat con mÃºltiples proveedores de LLM (local/remoto)
- BÃºsqueda semÃ¡ntica en documentos (RAG)
- AnÃ¡lisis de cÃ³digo
- Control de alucinaciones
- Herramientas extensibles

### **Â¿QuÃ© significa "Modo Agent" vs "Modo Manual"?**

- **Modo Agent**: La IA decide automÃ¡ticamente quÃ© herramientas usar (requiere OpenAI o Claude)
- **Modo Manual**: TÃº configuras quÃ© herramientas se ejecutan (funciona con cualquier LLM, incluso local)

---

## ğŸ› ï¸ InstalaciÃ³n

### **Â¿QuÃ© necesito instalar?**

**MÃ­nimo (local):**

- Python 3.11+
- Docker (para PostgreSQL, Qdrant, Redis)
- Ollama (para LLM local)

**Opcional (para providers remotos):**

- API keys de OpenAI, Claude, Gemini, etc.

### **Â¿Puedo usar sin Docker?**

SÃ­, pero tendrÃ­as que instalar PostgreSQL, Qdrant y Redis manualmente. Docker simplifica todo.

### **Â¿Funciona en Windows?**

SÃ­, pero necesitas:

- WSL2 (Windows Subsystem for Linux)
- Docker Desktop
- Python instalado en Windows o WSL

---

## ğŸ¤– LLM Providers

### **Â¿QuÃ© modelos puedo usar?**

**Local (gratis):**

- Mistral 7B
- Llama 2/3
- Phi-3
- Cualquier modelo de Ollama

**Remotos (requieren API key):**

- OpenAI: GPT-4, GPT-3.5
- Anthropic: Claude 3.5 Sonnet, Opus
- Google: Gemini Pro
- OpenRouter: Acceso a mÃºltiples modelos

### **Â¿CuÃ¡l es el mejor modelo para cada tarea?**

| Tarea            | Modelo Recomendado | Por quÃ©              |
|------------------|--------------------|----------------------|
| AnÃ¡lisis de docs | Claude 3.5 Sonnet  | Mejor contexto largo |
| Code review      | GPT-4              | Excelente con cÃ³digo |
| RAG bÃºsquedas    | Mistral (local)    | RÃ¡pido y econÃ³mico   |
| Creatividad      | GPT-4, Claude Opus | MÃ¡s imaginativos     |

### **Â¿CÃ³mo cambio de modelo?**

En la creaciÃ³n de conversaciÃ³n:

```json
{
  "settings": {
    "provider": "openai",  // o "local", "anthropic"
    "model": "gpt-4"       // o "mistral", "claude-3-5-sonnet"
  }
}
```

---

## ğŸ“š RAG (BÃºsqueda en Documentos)

### **Â¿CÃ³mo funciona RAG?**

1. Subes documentos â†’ Se procesan y guardan en Qdrant (base de datos vectorial)
2. Haces una pregunta â†’ El sistema busca partes relevantes del documento
3. La IA responde basÃ¡ndose en esos fragmentos

### **Â¿QuÃ© tipos de documentos soporta?**

- âœ… Markdown (.md)
- âœ… Word (.docx)
- âœ… PDF (.pdf)
- âœ… CÃ³digo fuente (.js, .ts, .py, .java, .sql)
- ğŸ”œ PowerPoint (.pptx) - prÃ³ximamente

### **Â¿CÃ³mo subo documentos?**

**OpciÃ³n 1: API**

```bash
curl -X POST http://localhost:8000/api/v1/files/upload \
  -F "file=@documento.pdf"
```

**OpciÃ³n 2: Sync completo (tu cÃ³digo existente)**

```python
from sync.syncer import QdrantSyncer
syncer = QdrantSyncer(vault_path='./data/vault')
syncer.sync()
```

### **Â¿QuÃ© es una "colecciÃ³n" en Qdrant?**

Una colecciÃ³n es como una "carpeta" de documentos relacionados. Por ejemplo:

- `api-documentation` â†’ Docs de tu API
- `plsql-procedures` â†’ Procedimientos almacenados
- `admin-manuals` â†’ Manuales administrativos

Puedes buscar en una o varias colecciones a la vez.

---

## ğŸ­ Prompts

### **Â¿QuÃ© es un prompt template?**

Una "receta" predefinida que le dice a la IA cÃ³mo comportarse. Por ejemplo:

- "Asistente de CÃ³digo" â†’ Experto en programaciÃ³n
- "Analista de Documentos" â†’ Extrae info precisa de docs

### **Â¿Puedo crear mis propios prompts?**

Â¡SÃ­! Desde la API:

```bash
POST /api/v1/prompts
```

O duplicar uno existente y modificarlo.

### **Â¿QuÃ© son las "variables" en un prompt?**

Campos dinÃ¡micos que el usuario completa. Por ejemplo:

```
Prompt: "Eres experto en {language} con {aÃ±os} de experiencia"
Variables:
  - language: "Python"
  - aÃ±os: 10
Resultado: "Eres experto en Python con 10 aÃ±os de experiencia"
```

---

## ğŸ›¡ï¸ Control de Alucinaciones

### **Â¿QuÃ© significa "modo estricto"?**

La IA **solo** responde con informaciÃ³n verificable de los documentos. Si no tiene la info, lo dice claramente.

### **Â¿CuÃ¡ndo usar cada modo?**

| Modo         | CuÃ¡ndo Usar                           | Temperature |
|--------------|---------------------------------------|-------------|
| **Strict**   | Contratos, docs legales, info crÃ­tica | 0.0 - 0.2   |
| **Balanced** | Uso general, anÃ¡lisis tÃ©cnico         | 0.3 - 0.5   |
| **Creative** | Brainstorming, ideas, exploraciÃ³n     | 0.7 - 1.0   |

### **Â¿CÃ³mo funciona la validaciÃ³n?**

En modo estricto, el sistema:

1. Verifica que cada respuesta tenga fuentes
2. Detecta frases especulativas ("probablemente", "podrÃ­a ser")
3. Asigna un "confidence score"
4. Puede rechazar responder si no hay fuentes

---

## ğŸ”§ Tools (Herramientas)

### **Â¿QuÃ© tools estÃ¡n disponibles?**

1. **RAG Search** - Busca en documentos

### **Â¿CÃ³mo agrego un nuevo tool?**

Crea una clase que herede de `BaseTool`:

```python
from tools.base_tool import BaseTool, ToolCategory, ToolResult


class MyCustomTool(BaseTool):
    @property
    def name(self) -> str:
        return "my_tool"

    async def execute(self, **kwargs) -> ToolResult:
        # Tu lÃ³gica aquÃ­
        return ToolResult(success=True, data={"result": "..."})


# Registrar
tool_registry.register(MyCustomTool())
```

### **Â¿CuÃ¡ndo usar modo Agent vs Manual?**

| Modo       | Ventajas                          | Desventajas                        |
|------------|-----------------------------------|------------------------------------|
| **Agent**  | AutomÃ¡tico, inteligente           | Requiere OpenAI/Claude, mÃ¡s caro   |
| **Manual** | Control total, funciona con local | Menos flexible, hay que configurar |

---

## ğŸ’¾ Base de Datos

### **Â¿Por quÃ© PostgreSQL?**

- Soporte de JSONB (flexible para metadata)
- Transacciones ACID
- Escalable
- Gratuito

### **Â¿QuÃ© guarda en la base de datos?**

- Conversaciones y mensajes
- Prompt templates
- ConfiguraciÃ³n de tools
- Metadata de archivos
- **NO** guarda los vectores (esos van en Qdrant)

### **Â¿Puedo usar otra base de datos?**

SÃ­, pero tendrÃ­as que adaptar los modelos SQLAlchemy. PostgreSQL es la opciÃ³n mÃ¡s probada.

---

## ğŸš€ Deployment

### **Â¿CÃ³mo lo despliego en producciÃ³n?**

El mismo cÃ³digo funciona en local y AWS:

1. **Cambiar .env:**
   ```bash
   DATABASE_URL=postgresql://user@rds-endpoint:5432/chatbot
   QDRANT_URL=https://your-qdrant-cloud.io
   ```

2. **Deploy options:**
    - AWS ECS/Fargate
    - EC2 con Docker
    - Kubernetes (si necesitas escalado masivo)

### **Â¿CuÃ¡nto cuesta?**

**Local:** Gratis (solo hardware)

**AWS (ejemplo):**

- RDS (PostgreSQL): ~$50/mes
- Qdrant Cloud: ~$50/mes (o self-hosted en EC2)
- ElastiCache (Redis): ~$15/mes
- ECS Fargate: ~$30/mes
- **Total:** ~$145/mes + costos de LLM APIs

**Costos de LLM:**

- Local (Ollama): $0
- GPT-4: ~$0.03/1K tokens
- Claude 3.5 Sonnet: ~$0.003/1K tokens

---

## ğŸ› Problemas Comunes

### **"Tool 'rag_search' not found"**

El tool no estÃ¡ registrado. Verifica en `main.py`:

```python
tool_registry.register(RAGTool())
```

### **"Conversation not found"**

EstÃ¡s usando un UUID incorrecto. Verifica con:

```bash
GET /api/v1/conversations
```

### **Ollama no responde**

```bash
# Verificar que estÃ© corriendo
ollama list

# Si no, iniciar
ollama serve
```

### **PostgreSQL connection failed**

```bash
# Verificar Docker
docker-compose ps

# Reiniciar
docker-compose restart postgres
```

---

## ğŸ“Š Performance

### **Â¿QuÃ© tan rÃ¡pido es?**

Depende del provider:

- **Local (Ollama)**: 5-20 tokens/seg (depende de tu GPU)
- **OpenAI API**: 30-50 tokens/seg
- **Claude API**: 40-60 tokens/seg

### **Â¿Puedo usar GPU?**

SÃ­, Ollama detecta automÃ¡ticamente la GPU. Para NVIDIA:

```bash
# Verificar
nvidia-smi

# Ollama usarÃ¡ GPU automÃ¡ticamente
```

### **Â¿CuÃ¡ntos usuarios soporta?**

Depende de tu infraestructura:

- **Local**: 1-5 usuarios concurrentes
- **AWS (small)**: 10-50 usuarios
- **AWS (scaled)**: 100+ usuarios (con load balancer)

---

## ğŸ” Seguridad

### **Â¿CÃ³mo protejo las API keys?**

- **Nunca** comitees `.env` a git
- Usa variables de entorno en producciÃ³n
- Rota keys periÃ³dicamente

### **Â¿Hay autenticaciÃ³n?**

No estÃ¡ implementada aÃºn. Para producciÃ³n, agrega:

- JWT tokens
- OAuth2
- API keys por usuario

### **Â¿Los datos estÃ¡n encriptados?**

- En trÃ¡nsito: SÃ­ (HTTPS en producciÃ³n)
- En reposo: Depende de tu DB (RDS soporta encryption)

---

Â¿MÃ¡s preguntas? Abre un issue en GitHub o contacta al equipo.
